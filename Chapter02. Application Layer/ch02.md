# Chapter 2: Application Layer

## 2.1 Principles of Network Applications 
*Creating a Network Application* 

- we consider the services provided transport layer and what is APIs in the Application layer to the transport layer services.
  
    At the core of network application development is writing programs that run on different end systems and communicate with each other over the network.
    For example, In Web applications 2 distinct programs communicate with each other: the browser program running in the user’s host & the Web server program running in the Web server host.
    

**2.1.1  Network Application Architectures**

From the application developer's perspective, **the network architecture** is fixed and provides a specific set of services to applications. The **application architecture**, on the other hand, is chosen by him. In choosing the application architecture, a developer will likely draw one of the **two predominant architectural paradigms** used in modern network applications:

<p align="center">
  <img width="530" alt="Screenshot 2024-09-30 at 12 48 47 PM" src="https://github.com/user-attachments/assets/5ac9b497-da55-4cc7-8d9c-d41380a1418d">
</p>

- **Client-server architecture**:
    
    *server always-on host*  which serves requests from many other hosts, called *clients*: [Web Browser and Web Server]. 
    
    *Clients* do not communicate directly with each other. The server has a permanent fixed, well-known address, called an IP address. Clients can always contact the server by sending a packet to the server’s IP address.
    
    Often, a single server host is incapable of keeping up with all the requests from clients, for this reason, a **data center**, housing a large number of hosts, is often used to create a powerful virtual server (via *proxyin*). data centers are used for scaling. 
    
- **P2P architecture**:
    
    *no always on server,* there is minimal or no reliance on dedicated servers in data centers, the application exploits direct communication between pairs of intermittently connected bots, called *peers*. 
    
    They are end systems owned and controlled by users. [Bittorrent, Skype]. 
    
    P2P applications provide **self-scalability** (the network load is distributed) new peers bring new service capacity, as well as new service demands & they are also **cost effective** since they don't require significant infrastructure and server bandwidth. new peers bring new
    
    P2P face challenges:
    
    1. ISP Friendly (asymmetric nature of residential ISPs)
    2. Security
    3. Incentives (convincing users to participate)

Some applications have hybrid architectures, such as for many instant messaging applications: a server keeps track of the IP addresses of users, but user-to-user messages are sent directly between users.

**2.1.2  Processes Communicating** 

*how the programs, running in multiple end systems, communicate with each other.*

- In operating systems, it's not programs but **processes** that communicate. A process can be thought of as (a program that is running within an end system)*
    
    When processes are running within **same host**, two processes communicate using inter-process communication (defined by OS) 
    
    Processes on **two different end systems** communicate with each other by exchanging **messages** across the computer network: a sending process creates and sends messages into the network, a receiving process receives these messages and possibly responds by sending messages back.
    
- **Client and Server Processes**
    
    A network application consists of pairs of processes that send messages to each other over a network. For each pair of communicating processes we label:
    
    **client →** the process that initiates the communication  [web browser]
    
    **server** → the process that waits to be contacted to begin the session  [web server]
    
- **The Interface Between the Process and the Computer Network**
    
    Any message sent from one process to another must go through the underlying network
    
    A process sends messages into, and receives messages from, the network through a software interface called a **socket**.* **A socket** is the interface between the application layer and the transport layer within a host, it is also referred to as the **Application Programming Interface** (**API**) between the application and the network.
      <p align="center">
  <img width="530" alt="Screenshot 2024-09-30 at 12 47 36 PM" src="https://github.com/user-attachments/assets/3ccf87ea-f21d-4205-8738-91d2231fe982">
  </p>
    There are two sockets involved whenever there is a sender and a receiver 
    
    The application at the sending side pushes messages through the socket. At the other side of the socket, the transport-layer protocol has the responsibility of getting the messages to the socket of the receiving process.
    
    The application developer has control of everything on the application-layer of the socket but has little control of the transport-layer side of the socket. The only control that he has over the transport-layer is:
    
    1. The choice of the transport protocol.
    2. Perhaps the ability to fix a few transport-layer parameters such as maximum buffer and maximum segment sizes.
- **Addressing Processes**
    
    In order for a process running on one host to send packets to a process running on another host, the receiving process needs to have an address. To receive messages, the process  must have ***identifier***
    
    To identify the receiving processes, two pieces of information need to be specified:
    
    1. **The address of the host.** In the Internet, the host is identified by its **IP Address**, a 32-bit (or 64) quantity that identifies the host uniquely.
    2. **An identifier that specifies the receiving process in the destination host:** the destination **port number**. Popular applications have been assigned specific port numbers (web server -> 80)
    
    extra note  : multiple processes can be running on the same device. Therefore, an IP address alone cannot identify which process is intended to receive a message. so  To distinguish between different processes running on the same host, a process must have an identifier.
    

**2.1.3  Transport Services Available to Applications** 

- What an Application-Layer Protocol Defines:
    1. **Types of messages exchanged**:  might define request, response messages.
    2. **Message syntax**: Defines the structure and layout of the message, (the fields & format)
    3. **Message semantics**:  the meaning of each field within the message.
    4. **Rules for message exchange**:  when and how processes (on different devices) should send and respond to messages, establishing the protocol for communication.
    
    **Types of protocols:**
    
    open protocols: defined in **RFCs** (Request for Comments), and anyone can access and use the protocol specifications.
    
    - allows  **interoperability**, meaning different systems can communicate using the same protocol.
    - e.g., HTTP, SMTP
    
    proprietary protocols: owned by a company or organization, and their specifications are not publicly available.
    
    - e.g., Skype, Zoom

**What are the services that a transport-layer protocol can offer to applications invoking it?**

1. **Reliable Data Transfer: Data Integrity** 
    
    For many applications, such as email, file transfer, web document transfers and financial applications, packet's drops and data loss can have devastating consequences. If a protocol provides guarantees that the data sent is delivered completely and correctly, it is said to provide **reliable data transfer**. The sending process can just pass its data into the socket and know with complete confidence that the data will arrive without errors at the receiving process.
    
    For **loss-tolerant applications**, most notably multimedia applications such as conversational audio/video that can tolerate some amount of data loss. In these multimedia applications, lost data might result in a small glitch in the audio/ video
    
2. **Throughput**
    
    Transport-layer protocol could provide guaranteed available throughput at some specific rate.The application could request a guaranteed throughput of *r* bits/sec, and the transport protocol would then ensure that the available throughput is always at least *r.*
    
    **Bandwidth-sensitive applications:** Applications that have throughput requirements 
    
    Many current multimedia applications are bandwidth sensitive, although some multimedia applications may use adaptive coding techniques to encode digitized voice or video at a rate that matches the currently available throughput.
    
    E**lastic applications use whatever** throughput as happens to be available. 
    
    ex: Electronic mail, file transfer, and Web transfers. 
    
3. **Timing**
    
    A transport-layer protocol can also provide timing guarantees. 
    
    Example: guarantees that every bit the sender pumps into the socket arrives at the receiver's socket no more than 100 msec later, appealing to Internet telephony, virtual environments, teleconferencing, and multiplayer games, all of which require tight timing constraints on data delivery in order to be effective (minimum delay). 
    
4. **Security**
    
    A transport-layer protocol can provide an application with one or more security services. It could encrypt all data transmitted by sending process and the receiving host decrypts it.This provides confidentiality between the two processes.
    

**2.1.4  Transport Services Provided by the Internet** 

The Internet makes two transport protocols available to applications: **TCP and UDP.**

The service requirements for some selected applications:
      <p align="center">
  <img width="530"  alt="Screenshot 2024-09-30 at 3 36 58 PM" src="https://github.com/user-attachments/assets/3b80b927-7ad3-4525-b6f1-1e3d1b3c2298">
  </p>
- **TCP Services**
    - *Connection-oriented service*: client and server exchange transport-layer control information *before* the application-level messages begin to flow. This  *handshaking* procedure alerts the client and server, allowing them to prepare for an onslaught of packets. Then a **TCP connection** is said to exist between the sockets of the two processes. When the application finishes sending messages, it must tear down the connection
    - *Reliable data transfer service:* delivers all data sent without error and in the proper order
    - *congestion-control mechanism:* throttles a sending process (client or server) when the network is congested between sender and receiver
- **UDP Services**
    
    UDP is a no-frills, lightweight transport protocol, providing minimal services. It is connectionless, there's no handshaking. 
    
    - The data transfer is unreliable: there are no guarantees that the message sent will ever reach the receiving process. Furthermore messages may arrive out of order.
    - Does not provide a congestion-control , **reliability,flow control, timing, throughput
    guarantee, security, or connection setup**
- **Securing TCP**
    
    Nether TCP nor UDP provides encryption.
    
    Thus, The Internet community has developed an enhancement for TCP, called **Transport Layer Security** (TLS) [RFC 5246]. **Secure Sockets Layer (SSL)**
    
    TCP-enhanced-with-TLS not only does everything that traditional TCP does but also provides critical process-to-process security services, including encryption, data integrity, and end-point authentication. 
    
    It is not a third protocol, but an enhancement of TCP, **the enhancement being implemented in the application layer** in both the client and the server side of the application (highly optimized libraries exist). SSL has its own socket API, similar to the traditional one. Sending processes passes cleartext data to the SSL socket which encrypts it.
    

**Services Not Provided by Internet Transport Protocols**
      <p align="center">
  <img width="530" alt="Screenshot 2024-09-30 at 3 37 28 PM" src="https://github.com/user-attachments/assets/4804e272-a5c2-4893-8e43-a243ed9fb68d">
  </p>
  

## 2.2 The Web and HTTP

**2.2.1 Overview of HTTP**

- The **HyperText Transfer Protocol (HTTP)**, the Web's application-layer protocol is a the heart of the Web.
    
    It is implemented in two programs: a client program and a server program. The two programs communicate other by exchanging HTTP messages.
    
- A **Web page** (or document) consists of objects.
    - An **object** is simply a file (HTML file, jpeg image...) that is *addressable by a single URL*.
    - Most Web pages consist of a **base HTML file** and several referenced objects.
    
    The HTML file references the other objects in the page with the objects' URLs. 
    
    Each URL has two components: (1) the hostname of the server that houses the object and (2) the object's path name. 
    
    `http://www.someSchool.edu/someDepartment/picture.gif`
    
     `www.someSchool.edu` →  hostname &  `/someDepartment/picture. gif` → path name.
    
- HTTP defines how Web clients request Web pages from Web servers and how servers transfer Web pages to clients.
    
    **Web Browsers** implement the client side of HTTP 
    
    **Web servers** implement the server side of HTTP
  <p align="center">
  <img width="530" alt="Screenshot 2024-10-01 at 9 39 13 AM" src="https://github.com/user-attachments/assets/ee33de7b-e897-407d-b0d4-b9063f5afca6" >
  </p>
    
    When a user requests a Web page (for example, clicks on a hyperlink), the browser sends HTTP request messages for the objects in the page to the server. 
    
    The server receives the requests and responds with HTTP response messages that contain the objects.
    
- HTTP uses TCP as its underlying transport protocol
    
    The HTTP client first initiates a TCP connection with the server (socket interface) port 80
    
    The Server accepts the connection
    
    Once the connection is established, the browser (HTTP client) and the server (HTTP server) processes access TCP (exchange msgs) through their socket interfaces.
    
- HTTP is a **stateless protocol: server maintains *no* information about past client requests**

**2.2.2 Non-Persistent and Persistent Connections**

In many Internet applications, the client and server communicate for an extended period of time, depending on the application and on how the application is being used, the series of requests may be back-to-back, periodically at regular intervals or intermittently. 

When this is happening over TCP, the developer must take an important decision: should each request/response pair be sent over a *separate* TCP connection or should all of the requests and their corresponding responses be sent over the *same* TCP connection? 

In the former approach, the application is said to use **non-persistent connections** and in the latter it is said to use **persistent connections** By default HTTP uses non-persistent connections but can be configured to be use persistent connections. 

To estimate the amount of time that elapses when a client requests the base HTML file until the entire file is received by the client we define the **round-trip time** (**RTT**) which is the time it takes for a small packet to travel from client to server and then back to the client.

***Non-persistent HTTP***

1. TCP connection opened
2. at most one object sent over TCP connection
3. TCP connection closed

downloading multiple objects required multiple connections (each object will req a new connection)

***Persistent HTTP***

TCP connection opened to a server

Multiple objects can be sent over *single* TCP connection between client, and that server

TCP connection closed

- **HTTP with Non-Persistent Connections**
      <p align="center">
  <img width="530"  alt="Screenshot 2024-10-01 at 9 39 43 AM" src="https://github.com/user-attachments/assets/6521b5e7-1bcd-43d4-8c81-5ccf2146f34a">
  </p>
  
**RTT (Round Trip Time)**: This is the time taken for a small packet to travel from the client to the server and back again. 

**HTTP response time (per object):**

one RTT to initiate TCP connection

one RTT for HTTP request and first few bytes of HTTP response to return

object/file transmission time

***Non-persistent HTTP response time = 2RTT+ file transmission time***
This model can be expensive on the server side: a new connection needs to be established for each requested object, for each connection a TCP buffer must be allocated along some memory to store TCP variables.

Non-persistent connections have some shortcomings:

1. additional overhead for each connection 
2.  delivery delay of two RTTs—one RTT to establish the TCP connection and one RTT to request/receive an object.
3. **browsers often open multiple parallel TCP connections to fetch referenced objects in**
parallel:  offsets the overhead caused by creating a new connection for each object by allowing multiple objects to be fetched in parallel.
- **HTTP with Persistent Connections**
    
    The server leaves the TCP connection open after sending a response, subsequent requests and responses between the same client and server will be sent over the same connection. 
    
    In particular an entire web page (text + objects) ca be sent over a single persistent TCP connection, multiple web pages residing on the same server can be sent from the server to the same client over a single persistent TCP connection.
    
    **These requests can be make back-to-back** without waiting for replies to pending requests (**pipelining**). When the server receives back-to-back requests, it sends the objects back-to-back. If connection isn't used for a pre-decided amount of time, it will be closed.
    
    as little as one RTT for all the referenced objects (cutting response time in half)
    

**2.2.3 HTTP Message Format**

There are two types of HTTP messages: ***request message* , *response message***

- **HTTP Request Message**
 <p align="center">
  <img width="530" alt="Screenshot 2024-10-01 at 9 40 31 AM" src="https://github.com/user-attachments/assets/08eeab73-9e2a-4e4d-a129-4ca5826a603b" >
  </p>
- Ordinary ASCII text
    - First line: **request line**
    - Other lines: **header lines**
    - the first lines has 3 fields: method field, URL field, HTTP version field:
        - method field possible values: `GET, POST, HEAD, PUT, DELETE`
- The majority of HTTP requests use the GET method, used to request an object.
 <p align="center">
  <img width="530" alt="Screenshot 2024-10-01 at 9 40 47 AM" src="https://github.com/user-attachments/assets/2f1b6f87-80f8-42a7-a14e-b842d2e5bc7c" >
  </p>
  
- **POST method:**
    - Often used when a web page includes a **form** for user input.
    - Data entered by the user (such as login credentials or form data) is sent from the client to the server in the **body** of the HTTP POST request message.
    - Unlike GET, the data is not visible in the URL, making it more secure for sensitive data.
- **GET method (for sending data to server):**
    - Primarily used for retrieving data from a server.
    - Data (like search queries) is included directly in the **URL** after a '?'.
    Example: `www.somesite.com/animalsearch?monkeys&banana`.
    - It's suitable for fetching data where no sensitive information is involved, as the data is visible in the URL.
- **HEAD method:**
    - Similar to the GET method but only requests the **headers** of the HTTP response, not the actual content (or body).
    - Useful for checking what would be returned for a URL (like checking the modification date) without downloading the entire resource.
- **PUT method:**
    - Used for **uploading** new files or objects to the server.
    - If the resource already exists, the PUT request **replaces** it with the new content from the request body.
    - It's typically used for updating files or data on the server.

**HTTP Response Message**

A typical HTTP response message:
 <p align="center">
  <img width="530" alt="Screenshot 2024-10-01 at 9 41 16 AM" src="https://github.com/user-attachments/assets/0159dd6e-b747-46fd-bc73-dff6183339df" >
  </p>
  
- Status line: protocol version, status code, corresponding status message
- six header lines:
    - the connection will be closed after sending the message
    - date and time when the response was created (when the server retrieves the object from the file system, insert object in the message, sends the response message)
    - Type of the server / software
    - Last modified: useful for object caching
    - Content-Length: number of bytes in the object
    - Content-Type
- entity body: contains the requested object itself (data)
 <p align="center">
  <img width="530" alt="Screenshot 2024-10-01 at 9 41 39 AM" src="https://github.com/user-attachments/assets/f40b9488-0936-44b1-be32-c2b00884c2f7" >
  </p>
  
- Some common status codes:
    - `200 OK`: request succeeded, information returned
    - `301 Moved Permanently`: the object has moved, the new location is specified in the header of the response
    - `400 Bad Request`: generic error code, request not understood
    - `404 Not Found`: The requested document doesn't exist on the server
    - `505 HTTP Version Not Supported`

**2.2.4 User-Server Interaction: Cookies**

HTTP server is *stateless (does not retain info about clients )* in order to simplify server design and improves performances. However,  A website can identify users using **cookies** either to restrict user access, or to serve content as a function of the user identity (Displaying content tailored to a specific use)

- Cookie technology has 4 components:
    1. Cookie header in HTTP response message
    2. Cookie header in HTTP request message
    3. Cookie file on the user's end-system managed by the browser
    4. Back-end database at the Website
 <p align="center">
  <img width="530"alt="Screenshot 2024-10-01 at 9 42 09 AM" src="https://github.com/user-attachments/assets/c22bc3aa-fee6-4d9a-8d6e-2a079727a6c6" >
  </p>
User connects to website using cookies:

- Server creates a unique identification number and creates an entry in its back-end database indexed by the identification number -server responds to user's browser including in the header: `Set-cookie: identification number`
- The browser will append to the cookie file the hostname of the server and the identification number header
- Each time the browser will request a page, it will consult the cookie file, extract the identification number for the site and put a cookie header line including the identification number

The server can track the user's activity: it knows exactly what pages, in which order and at what times that identification number has visited. This is also why cookies are controversial: a website can learn a lot about a user and sell this information to a third party.

Therefore **cookies can be used to create a user session layer on top of stateless HTTP**.

- ***What cookies can be used for:*** authorization, shopping carts, recommendations, user session state (Web e-mail)
- *Challenge: How to keep state? at protocol endpoints:* maintain state at sender/receiver over multiple transactions *in messages:* cookies in HTTP messages carry state
    
    

**2.2.5 Web Caching**

A **Web cache**, also called **proxy server** is a network entity that satisfies HTTP requests on behalf of an origin Web server. 

It has its own disk storage and keeps copies of recently requested objects in this storage.

- **user’s browser configured so that all the HTTP requests are first directed to the (local) Web cache.**
    
    browser sends all HTTP requests to cache; *if* object in cache: cache returns object to client *else* cache requests object from origin server, caches received object, then returns object to client
    
1. The browser establishes a TCP connection to the web cache, sending an HTTP request for the object to the Web cache.
2. The web cache checks to see if it has a copy of the object stored locally. If yes, it will return it within an HTTP response message to the browser.
3. If not, the Web cache opens a TCP connection to the origin server, which responds with the requested object.
4. The Web caches receives the object, stores a copy in its storage and sends a copy, within an HTTP response message, to the browser over the existing TCP connection.

Therefore a **cache is both a server and a client at the same time**. Usually caches are purchased and installed by ISPs. They can substantially reduce the response time for a client request and substantially reduce traffic on an institution's access link to the Internet.

- **server tells cache about object’s allowable caching in response header**
    - **`Cache-Control: max-age=<seconds>**:` Specifies how long the object can be cached (in seconds).
    - **`Cache-Control: no-cache**:` Indicates that the object should not be cached and should always be fetched from the origin server.
- **Why Use Web Caching?**
    1. **Reduce Response Time**: The cache is usually **closer to the client** (geographically or network-wise), meaning the client can get the requested content faster compared to fetching it from the origin server.
    2. **Reduce Traffic on an Institution's Access Link**: By serving cached content locally, web caches help reduce the amount of data sent over an institution’s access link to the internet, **reducing bandwidth costs**.
    3. **Dense Internet with Caches**: The internet is filled with caches, which helps even content providers with limited resources ("poor" content providers) to **deliver their content more efficiently**. Since many users are served by caches, the load on the origin server is reduced.
- **Caching example:**
    
    **Scenario**:
    
    **Access link rate**: 1.54 Mbps (connection speed between the institutional network and the public internet).
    
    **Round Trip Time (RTT)** from the institutional router to the origin server: 2 seconds (the time it takes for a packet to travel to the server and back).
    
    **Web object size**: 100 Kbits (the size of the requested web content).
    
    **Average request rate**: 15 requests per second sent from browsers to origin servers.
    
    *Formula for Total Response Time: The total response time is the time from the browser’s request of an object until its receipt of the object.*
    
    $End-to-end delay=Internet delay+Access link delay+LAN delay$
    
    **Performance Calculation:**
    
    1. **Access Link Delay**:
        
        **Average data rate (Traffic)**:
        $\text{Traffic} = \text{Request rate} \times \text{Object size} = 15 \times \frac{100Kbits}{1000} = 1.5 \text{ Mbps}$
        
        **Access link utilization**:
        $\text{Utilization} = \frac{\text{Traffic}}{\text{Access link rate}} = \frac{1.5}{1.54} \approx 0.97$
        
        **Internet delay**: From the graph, delays increase significantly as utilization approaches 1. In this case, the delay for the access link is expressed in **minutes**.
        
    2. **LAN Delay**:
        
        **Average data rate (Traffic)**:
        $\text{Traffic} = \text{Request rate} \times \text{Object size} = 15 \times \frac{100}{1000} = 1.5 \text{ Mbps}$
        
        **LAN utilization**:
        $\text{Utilization} = \frac{\text{Traffic}}{\text{LAN rate}} = \frac{1.5}{1000} = 0.0015$
        
        **LAN delay**: From the graph, the delay in the LAN is measured in **microseconds (usecs)** because the LAN is much faster.
        
    
    Total End-to-End Delay:
    
    **End-to-end delay** = 2 seconds (Internet delay) + minutes (Access link delay) + microseconds (LAN delay)
    
    The significant delay comes from the **access link** since the utilization is very high (0.97), leading to a longer delay.
    

…

- Conditional GET is a mechanism that ensures the updated version of an object in the cache.
    - An HTTP request message is a so-called conditional GET message if:
        - The request message uses the GET method.
        - The request message includes an "IF-Modified-Since:" header line.
    
    *Goal:* don’t send object if browser has up-to-date cached version
    
    no object transmission delay (or use of network resources)
    
    - *client:* specify date of browser- cached copy in HTTP request
    
    **If-modified-since: <date>**
    
    - *server:* response contains no object if browser-cached copy is up-to-date:
    
    **HTTP/1.0 304 Not Modified**
    
- **HTTP/2**
    
    ***Key goal:* decreased delay in multi-object HTTP requests**
    
    - *HTTP1.1:* introduced multiple, pipelined GETs over single TCP connection
        - server responds *in-order* (FCFS: first-come-first-served scheduling) to GET requests
        - with FCFS, small object may have to wait for transmission (head-of- line (HOL) blocking) behind large object(s)
        - loss recovery (retransmitting lost TCP segments) stalls object transmission
    - ***HTTP/2:*** [RFC 7540, 2015]  **increased flexibility at  *server* in sending** objects to client:
        - methods, status codes, most header fields unchanged from HTTP 1.1
        - transmission order of requested objects based on client-specified object priority (not necessarily FCFS)
        - *push* unrequested objects to client
        - divide objects into frames, schedule frames to mitigate HOL blocking
           <p align="center">
             <img width="530" alt="Screenshot 2024-10-01 at 9 42 40 AM" src="https://github.com/user-attachments/assets/8b8ae59b-2759-4061-9d00-1472e22d6a3d" >
           </p>
           <p align="center">
             <img width="530" alt="Screenshot 2024-10-01 at 9 43 05 AM" src="https://github.com/user-attachments/assets/6cf1e22d-1065-4e71-a578-417cb8b9ed33" >
           </p>
            
    - HTTP/2 over single TCP connection means:
        - recovery from packet loss still stalls all object transmissions as in HTTP 1.1, browsers have incentive to open multiple parallel TCP connections to reduce stalling, increase overall throughput
        - no security over vanilla TCP connection
        - HTTP/3: adds security, per object error- and congestion-control (more pipelining) over UDP more on HTTP/3 in transport layer


## 2.3 Electronic Mail in the Internet

> A typical message starts its journey in the sender’s user agent, then travels to the sender’s mail server, and then travels to the recipient’s mail server, where it is deposited in the recipient’s mailbox. Reattempts are often done every 30 minutes
> 

**2.3.1 Email Components**

Three major components: **user agents**, **mail servers**, & **Simple Mail Transfer Protocol (SMTP)**

- **User Agents:(mail reader)** User agents allow users to read, reply to, forward, save, and compose messages
    
    Tools like Microsoft Outlook, Apple Mail, and Gmail, allowing users to manage emails.
    
    outgoing, incoming messages are  stored on server
    
- **Mail Servers:** The central infrastructure, hosting mailboxes for recipients like Bob.
    
    mailbox: manages and maintains incoming messages
    
    message queue:  outgoing messages are placed in the mail server’s outgoing message queue
    
- **SMTP (Simple Mail Transfer Protocol):** The principal protocol to send emails between servers.

A typical message starts its journey in the sender’s user agent, then travels to the sender’s mail server, and then travels to the recipient’s mail server, where it is deposited in the recipient’s mailbox.

**2.3.2 SMTP Basics (RFC 5321)**

- SMTP transfers messages between sender and recipient mail servers at `Port 25`.
- The client (sender's server) initiates a connection to the recipient's server via TCP to reliably transfer the messages.
- direct transfer: sending server (acting like client) to receiving server (acting like server)
           <p align="center">
             <img width="530" alt="Screenshot 2024-10-01 at 9 36 18 AM" src="https://github.com/user-attachments/assets/0a1af197-27f4-4ea4-813c-e2e62ace735d">
           </p>

```
-------SIMPLE SMTP INTERACTION -------
S: 220 hamburger.edu
C: HELO crepes.fr
S: 250 Hello crepes.fr, pleased to meet you -> HandShake 
C: MAIL FROM: <alice@crepes.fr>
S: 250 alice@crepes.fr ... Sender ok
C: RCPT TO: <bob@hamburger.edu>
S: 250 bob@hamburger.edu ... Recipient ok
C: DATA
S: 354 Enter mail, end with ”.” on a line by itself
C: Do you like ketchup?
C: How about pickles?
C: . -> Termninated  
S: 250 Message accepted for delivery
C: QUIT
S: 221 hamburger.edu closing connection
```

- It introduces the sender and recipient, transmits the message, and uses a persistent connection for multiple messages.
  <p align="center">
    <img width="530" alt="Screenshot 2024-10-01 at 9 35 51 AM" src="https://github.com/user-attachments/assets/3dc5e9ba-42f8-4fa1-8525-0a6dfe0ab5b5">
  </p>

**2.3.3 Mail Message Formats**

- Email messages consist of a `header` and a `body`.
- The `header` includes sender and recipient information, `"From," "To," and "Subject."`.
    
    `From: alice@crepes.fr`
    
    `To: bob@hamburger.edu`
    
    `Subject: Searching for the meaning of life.`
    
    headers are distinct from SMTP commands used for server handshake communication.
    
    The header lines and the body of the message are separated by a blank line (that is, by CRLF).
    
- `Body`: the “message” , ASCII characters only

**2.3.3 Mail Access Protocols**
  <p align="center">
    <img width="530" alt="Screenshot 2024-10-01 at 9 35 33 AM" src="https://github.com/user-attachments/assets/700da595-9fb1-49ac-afc2-f32d3199ad74">
  </p>
  
> Bob’s user agent can’t use SMTP to obtain the messages because obtaining the messages is a pull operation, whereas **SMTP is a push protocol.**
> 
- `SMTP`: delivery/storage of e-mail messages to receiver’s server
- Users retrieve their email messages from a shared mail server using either `HTTP or IMAP.`
    
    IMAP: [RFC 3501]: messages stored on server, IMAP provides retrieval, deletion, folders of stored messages on server
    
- HTTP is often used for web based email clients like Gmail, while IMAP is common with clients like Microsoft Outlook.
    
    HTTP: gmail, Hotmail, Yahoo!Mail, etc. provides web-based interface on top of STMP (to send), IMAP (or POP) to retrieve e-mail messages
    
- Both the HTTP & IMAP approaches allow to manage folders, move messages to folders, delete messages, mark messages as important, and so on.
- **SMTP: *comparison with HTTP***
    
    
    | Feature | **HTTP** | **SMTP** |
    | --- | --- | --- |
    | **Purpose** | Transfers files from a web server to a client | Transfers files between mail servers |
    | **Client Interaction** | Client **pull** (requests data) | Client **push** (sends data) |
    | **Encapsulation** | Each object encapsulated in its own message | Multiple objects sent in a multipart message |
    | **Data Format** | No restriction on data format | Requires 7-bit ASCII for messages |
    | **Connection Type** | Uses persistent connections | Uses persistent connections |
    | **Command Interaction** | ASCII command/response, status codes | ASCII command/response, status codes |
    | **End of Message** | No specific delimiter | `CRLF.CRLF` to mark the end of a message |

## **2.4 DNS—The Internet’s Directory Service**

- One identifier for a host is its **hostname** [`cnn.com`, `www.yahoo.com`]. Hostnames are mnemonic and therefore used by humans. Hosts are also identified by **IP addresses**.
    
    People prefer the more mnemonic hostname identifier, while routers prefer fixed length, hierarchically structured IP addresses.
    

**2.4.1 Services Provided by DNS**

- **DNS** is an directory service that translates human friendly hostnames into IP addresses. It’s:
    1. A distributed database implemented in a hierarchy of **DNS Servers**
    2. An application-layer protocol that allows hosts to query the distributed database.
- **DNS servers** are often UNIX machines running  **B**erkeley **I**nternet **N**ame **D**omaine (`BIND`) software.
- **DNS runs over UDP and uses port 53** It is often employed by other application-layer protocols (HTTP, FTP...) to translate user-supplied hostnames to IP addresses.
    
    **Implemented as application-layer protocol at the edge of the network**
    
- **DNS services include:**
    - **Hostname-to-IP-address translation**: The primary function of DNS is to translate human-readable domain names (`www.example.com`) into IP addresses that computers use to communicate.
    - **hostname aliasing**: host with a complicated canonical hostname can have one or more alias names.
        
        `relay1.west-coast.enterprise.com` →`(canonical/official website name)`
        
        `enterprise.com` →`(alias name)`
        
    - **Mail Server Aliasing**: DNS resolves alias hostnames to canonical forms for mail servers and retrieves corresponding IP addresses.
        
        Used to make email servers' hostnames more mnemonic. This also allows for an e-mail server and an Web server to have the same hostname.
        
        `bob@yahoo.com` → `bob@relay1.west-coast.yahoo.com`
        
    - **Load Distribution**: DNS balances traffic among replicated servers by rotating IP addresses within replies, ensuring even distribution.
        
        This technique is also applied to email servers with shared alias names.
        
        Replicated servers can have the same hostname. In this case, a set of IP addresses is associated with one canonical hostname. When a client make a DNS query for a name mapped to a set of addresses, the server responds with the entire set, but rotates the ordering within each reply.
        

**2.5.2 Overview of How DNS Works**

> `gethostbyname()` is the function call that an application calls in order to perform the translation.
> 
- **Why Not Centralize DNS?**
    
    **DNS is decentralized** instead of relying on a single central server
    
    - **Single point of failure**: If a centralized server fails, the entire system would collapse.
    - **Traffic volume**: A single centralized DNS server would be overwhelmed by the vast number of DNS queries occurring from 100s of hosts.
    - **Geographical distance**: A centralized server cannot be physically close to all clients, resulting in **significant delays** due to network latency.
    - **Maintenance**: The single DNS server would have to keep records for all Internet hosts
    Maintaining a single server handling all DNS traffic would be complex and impractical.
- Centralization Does Not Scale: a single server simply **doesn't scale** due to the massive number of DNS queries worldwide. (not feasible due to scalability issues)
    
    Example: **Comcast** handles 600 billion DNS queries per day, and **Akamai** handles 2.2 trillion DNS queries per day.
    
- DNS operates through query and reply messages using UDP datagrams on port 53.
- **A Homogeneous Distributed, Hierarchical Database**
    <p align="center">
    <img width="530" alt="Screenshot 2024-10-01 at 9 34 58 AM" src="https://github.com/user-attachments/assets/8ce16d23-bf9a-48d0-ada6-925d1813dc74">
  </p>
    
    - DNS uses three classes of servers: `Root` DNS servers, `top level domain (TLD)` DNS servers, and `authoritative` DNS servers.
    - **Client wants IP address for  [www.amazon.com](http://www.amazon.com) ; 1**st **approximation:**
        - client queries root server to find .com DNS server
        - client queries .com DNS server to get amazon.com DNS server
        - client queries amazon.com DNS server to get IP address for www.amazon.com
    
    **The three classes of DNS servers:**
    
    - **Root DNS servers**: In the Internet there are 13 root DNS servers, most hosted in North America, each of these is in reality a network of replicated servers, for both security and reliability purposes (total: 247)
        
        ICANN (Internet Corporation for Assigned Names and Numbers) manages root DNS domain
        
    - **Top-level domain (TLD) servers**: responsible for top-level domains such as .com .org .net .edu and .gov and all of the country top-level domains .uk .fr .jp
    - **Authoritative DNS servers**: every organization with publicly accessible hosts must provide publicly accessible DNS records that map the names of those hosts to IP addresses.
        
        An organization can choose to **implement its own authoritative DNS server** or to pay to have the **records stored in an authoritative DNS of some service provider.**
        
- Root DNS servers provide IP addresses for TLD servers. TLD servers provide IP addresses for authoritative DNS servers Authoritative DNS servers store DNS records for specific organizations.
- A `local DNS server`, specific to an ISP, also plays a crucial role in DNS queries. It cache DNS information to reduce query traffic and improve performance.
    
    *When a host makes a DNS query, the query is sent to the local DNS server, which acts a proxy, forwarding the query into the DNS server hierarchy.
    
    - each ISP has local DNS name server; to find yours:
        
         `MacOS: % scutil --dns , Windows: >ipconfig /all`
        
- DNS extensively utilizes caching to enhance performance. These are stored temporarily and it allows DNS servers to quickly respond to subsequent queries for the same hostname.

 **- Recursive vs Iterative DNS Queries**
     <p align="center">
    <img width="650" alt="Screenshot 2024-10-01 at 9 34 38 AM" src="https://github.com/user-attachments/assets/35d024f6-2a3d-4e28-9771-a0906c7c9b71">
  </p>
    
In **iterative queries** the same machine sends requests and receives replies. Any DNS can be iterative or recursive or both.

In an **iterated query**, the DNS server that is contacted by the requesting client does not resolve the query completely. Instead, it responds with the next server that might know the answer, and the client has to contact that server. (contacted server replies with name of server to contact “I don’t know this name, but ask this server) 

In **recursive queries** the user sends the request its nearest DNS which will ask to a higher-tier server, which will ask to lower order... the chain goes on until it reaches a DNS that can reply, the reply will follow the inverse path that the request had.

 In a **recursive query**, the entire burden of resolving the domain name is placed on the contacted DNS server. The server that receives the query resolves the domain name completely by contacting other servers on behalf of the client.

- **DNS Caching**
    
    **improves the delay performance and to reduce the number of DNS messages ricocheting around the Internet.** 
    
    In a query chain, when a DNS receives a DNS reply it can cache the mapping in its local memory.
    
    - **Once any name server learns a mapping**: When a DNS server queries and receives a domain-to-IP mapping, it stores (or **caches**) that mapping.  and **i*mmediately*** returns a cached mapping in response to a query.
    - cache entries timeout (disappear) after some time (TTL)
    - TLD servers typically cached in local name servers
    - Cached entries may be out-of-date: If a host changes its IP address, the cached entry might still reflect the old IP address until the TTL expires. This delay can lead to outdated information being served, causing temporary connectivity issues.

**2.4.3 DNS Records and Messages**

- DNS servers store **resource records (RRs)** in the distributed database.that provide hostname-to-IP address mappings.Each DNS reply messages carries one or more resource records.
- A resource record (RR) is a four tuple: `(Name, Value, Type, TTL)`.
    
    **TTL** (Time to Live) determines when a resource should be removed from a cache.
    
    - Types of resource records:
        
        
        | Type | Name | Value |
        | --- | --- | --- |
        | `Type=A` Standard  hostname to IP address | a hostname | IP address |
        | `Type=NS`  Maps a domain to the hostname of an authoritative DNS server. | a domain (foo.com) | hostname of an authoritative DNS server.  Used to route queries further along in the query chain |
        | `Type=CNAME` Provides the canonical name for an alias hostname. | a alias name | canonical hostname for the name in Name  ****`www.ibm.com`  **is really →**  `servereast.backup2.ibm.com ****` |
        | `Type=MX` Maps to the canonical name of a mail server with an alias hostname. | alias hostname |  ****value **is name of SMTP mail server associated with name** canonical hostname of a mail server that has an alias hostname Name |
        
        To obtain the canonical name for the mail server, a DNS client would query for an MX record; to obtain the canonical name for the other server, the DNS client would query for the CNAME record.
        
- **DNS Messages**

The only types of DNS messages are DNS queries and reply messages. They have the same format:
<p align="center">
  <img width="650" alt="Screenshot 2024-10-01 at 9 33 51 AM" src="https://github.com/user-attachments/assets/04a34883-d40a-45e5-bd96-8f0d9fdbe6de">
  </p>

- First 12 bytes in the **`*header section*:`** 16-bit number identifying the query, which will be copied into the reply query so that the client can match received replies with sent queries.
    - Flags: There are a number of flags in the flag field. (0 query, 1 reply).
        - 1 bit flag authoritative flag set in **reply messages** when DNS server is an authoritative for a queried name.
        - 1 bit recursion flag if the **client** desires that the server performs recursion when **it doesn't have a record**
        - 1 bit recursion-available field is set in the reply if the **DNS server supports recursion**
    - There are four number-of fields: These fields indicate the number of occurrences of the four types of data sections that follow the header
- `*question section*:` information about the query: (1) name field containing the name being queried, (2) type field that indicates the type of question asked about the name
    
    ex: a host address associated with a name (Type A) or the mail server for a name (Type MX).
    
- `*answer section*:`resource records for the name originally queried: Type, Value, TTL. Multiple RRs can be returned if the server has multiple IP addresses
- `*authority section*:` records for other authoritative servers.
- `*additional section*:`other helpful records: canonical hostnames...

- **Inserting Records into the DNS Database**
    
    A **registrar** is responsible for verifying the uniqueness of the domain name, entering it into the DNS database, and collecting a fee for the service.
    
    1. **Register Domain Name**:
        
        We create a new company called **`NewCompany`**, and we need to register the domain name `newcompany.com` with a **DNS registrar** (ex:Network Solutions).
        
    2. **Provide DNS Server Information to the Registrar**:
        
        During registration, we must provide the **names and IP addresses** of our primary and secondary **authoritative DNS servers**.
        
        For example, the primary DNS server might be `dns1.newcompany.com` with IP `212.2.212.1`, and the secondary server might be `dns2.newcompany.com` with IP `212.212.212.2`.
        
    3. **Registrar Enters Records into the DNS Database**:
        
        The registrar will ensure that two types of records are inserted into the **TLD (Top-Level Domain)** servers:
        
        - **Type NS (Name Server)** record: This links the domain (`newcompany.com`) to the name of the authoritative DNS server (`dns1.newcompany.com`).
        - **Type A (Address)** record: This maps the DNS server (`dns1.newcompany.com`) to its IP address (`212.212.212.1`).
    4. **Insert Additional Records into the Authoritative DNS Servers**:
        
        After the domain is registered, we need to ensure that additional resource records are added to the **authoritative DNS server** (e.g., `dns1.newcompany.com`):
        
        - **Type A record**: This points `www.newcompany.com` to the IP address of the web server.
        - **Type MX (Mail Exchange) record**: This directs email for `newcompany.com` to the appropriate mail server (e.g., `mail.newcompany.com`).
    
    ***When Alice in Australia wants to view the Web page www.networkutopia.com.***
    
    1. Alice’s host will first send a DNS query to her local DNS server.
    2. The local DNS server will then contact a TLD com server. (if the address of a TLD com server is not cached.)
    3. This TLD server contains the Type NS and Type A resource records (the registrar had these resource records inserted into all of the TLD com servers).
    4. The TLD com server sends a reply to Alice’s local DNS server, with the reply containing the two resource records.
    5. The local DNS server then sends a DNS query to 212.212.212.1, asking for the Type A record corresponding to www.networkutopia.com.
    6. This record provides the IP address of the desired Web server, say, 212.212.71.4, which the local DNS server passes back to Alice’s host.
    
    **Alice’s browser can now initiate a TCP connection to the host 212.212.71.4 and send an HTTP request over the connection.**
    
- **Focus on security: DNS vulnerabilities**
    - DDoS Attacks:  bandwidth-flooding attack against DNS servers
        
        an attacker could attempt to send to each DNS root server a deluge of packets, so many that the majority of legitimate DNS queries never get answered.
        
        not successful : DNS root servers were protected by packet filters & local DNS servers cache IPs of TLD servers, allowing root server bypass
        
    - MITM: the MITM answers queries with false replies tricking the user into connecting to another server.
        
        the attacker intercepts queries from hosts and returns bogus replies. 
        
        solution :  ( DNS Security Extensions DNSSEC [Gieben 2004; RFC 4033]  and **DNS cache poisoning**)
        
    - The DNS infrastructure can be used to launch a DDoS attack against a targeted host

To date, there hasn't been an attack that that has successfully impeded the DNS service, DNS has demonstrated itself to be surprisingly robust against attacks. However there have been successful reflector attacks, these can be addressed by appropriate configuration of DNS servers.

## 2.5 Peer-to-Peer File Distribution
**Peer-to-Peer (P2P) Architecture**:

- There is **no always-on server** in P2P.
- Arbitrary **end systems** (peers) communicate directly.
- Peers request services from each other and provide services in return, which allows for **self-scalability** — as more peers join, they bring both service capacity and demand.
- Peers are intermittently connected and change their IP addresses.
- Examples include **P2P file sharing** (BitTorrent), **streaming** ( KanKan), and **VoIP** (Skype).

**File distribution: client-server vs P2P**

In **client-server** file distribution, the server must send a copy of the file to each of the peers—placing an enormous burden on the server and consuming a large amount of server bandwidth.

In **P2P** file distribution, each peer can redistribute any portion of the file it has received to any other peers, thereby assisting the server in the distribution process. As of 2016, the most popular P2P file distribution protocol is BitTorrent.

**Time to Distribute a File (Client-Server vs P2P)**:

**How much time** does it take to distribute a file (of size F) from one server to N peers?

Factors influencing this include:

- The server's **upload capacity** ($u_s$),
- Peers' **download capacities** ($d_1, d_2, ..., d_N$),
- Peers' **upload capacities** ($u_1, u_2, ..., u_N$).
<img width="600" alt="Screenshot 2024-10-19 at 9 59 18 PM" src="https://github.com/user-attachments/assets/3f025886-4d49-49d1-a54c-c5f0a2ba3678">
**File Distribution Time in Client-Server Model & P2P Model**:

| **Aspect** | **Client-Server Model** | **P2P Model** |
| --- | --- | --- |
| **Definition** | The time it takes to distribute a file to all N clients. | The time it takes to distribute a file by leveraging both server and peer-to-peer distribution. |
| **Server Transmission** | The server must send a copy of the file to each of the N peers. The time to send one copy is ( $F / u_s$ ), where ( $u_s$ ) is the server's upload rate. The time to send N copies is ( $NF / u_s$ ). | The server must send at least one copy of the file. The time to send one copy is ( $F / u_s$ ). |
| **Client Download** | Each client must download the file at its own rate. The minimum time is determined by the client with the slowest download speed ( $d_{\min}$ ). The minimum download time is ( $F / d_{\min}$ ). | Each client downloads the file at its own rate, with the slowest client taking ( $F / d_{\min}$ ) |
| **Client Upload** | Not applicable in this model as only the server uploads. | Peers upload portions of the file to other peers. The system’s total upload capacity is the sum of the server’s upload rate and the upload rates of all peers ( $u_s + \sum u_i$ ). |
| **Overall Time** | The total time to distribute the file to N clients is the greater of the time for the server to upload all copies or the slowest client to download the file. This is expressed as: $( D_{C-S} \geq \max(NF / u_s, F / d_{\min}) )$ | The time to distribute the file depends on both the server's and peers' combined upload capacities. The formula is: $( D_{P2P} \geq \max(F / u_s, F / d_{\min}, NF / (u_s + \sum u_i)) ).$ |
| **Efficiency with N** | This time increases **linearly** with N, meaning the server becomes a bottleneck as the number of clients grows. | As N increases, the total upload capacity increases as well, because more peers contribute their upload bandwidth, mitigating the linear growth seen in the client-server model. |
  

<img width="300" alt="Screenshot 2024-10-19 at 10 06 19 PM" src="https://github.com/user-attachments/assets/1bc1f6b5-3ce8-4d5c-b5c9-12bbde12ca9f">


**P2P file distribution: BitTorrent**
- In BitTorrent the collection of all peers participating in the distribution of a particular file is called a *torrent*.
- Peers in a torrent download equal-size *chunks* of the file from one another with a typical chunk size of 256 KBytes.
- There are two main entities:
    - **Tracker**: It tracks all the peers participating in the torrent.
      The tracker will send a list of IP addresses for peers who are currently exchanging the requested file chunks in a torrent
    - **Torrent**: This represents the group of peers that are exchanging chunks of a file.
- When a new peer, like Alice, joins the torrent, she gets a list of peers from the tracker and starts exchanging file chunks.
<p align="center">
  <img width="650" alt="Screenshot 2024-10-19 at 9 32 42 PM" src="https://github.com/user-attachments/assets/7a0a4bdd-1381-45f1-b6e6-a6c4390628f6"> >
  </p>
  
**BitTorrent: requesting, sending file chunks**

Peer Joining the Torrent:

When a peer joins, it starts with no file chunks but accumulates them over time from other peers.

The peer registers with a tracker to get a list of peers, known as “neighbors.”

While downloading, the peer also uploads chunks to others.

Churn refers to the dynamic nature of peers joining and leaving the torrent.

Once a peer has the complete file, it can either leave the network selfishly or stay altruistically to help other peers.

**Requesting and Sending File Chunks**:

- **Requesting chunks**:
  
    - Peers have different subsets of the file at any given time.
      
    - Periodically, peers ask for lists of chunks other peers possess and request the **rarest chunks first** to increase file availability, used to distribute the file chunks equally ni the torrent.
      
- **Sending chunks (Tit-for-Tat)**:
  
    - A peer sends chunks to its top four peers who are sending chunks back at the highest rate.
      
    - Every 30 seconds, one random peer is “**optimistically unchoked**,” meaning it is allowed to send chunks even if it’s not in the top four.

**BitTorrent: tit-for-tat**

(1) Alice “optimistically unchokes” Bob

(2) Alice becomes one of Bob’s top-four providers; Bob reciprocates 

(3) Bob becomes one of Alice’s top-four providers

<p align="center">
  <img width="650" alt="Screenshot 2024-10-19 at 9 22 59 PM" src="https://github.com/user-attachments/assets/0d7f250d-6e22-4dce-a1ba-cc41aa3bc42e" >
  </p>


